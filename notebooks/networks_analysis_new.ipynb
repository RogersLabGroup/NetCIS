{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental design\n",
    "\n",
    "### Biological\n",
    "\n",
    "- Mice with sleeping beauty\n",
    "- harvest left/right tumor and spleen after transposition\n",
    "- amplification at IRR and IRL sites of transposon\n",
    "- Illumina paired reads\n",
    "\n",
    "### Computational\n",
    "\n",
    "- preprocess reads\n",
    "- preprocess insertions\n",
    "- get read counts grouped by interstion sites (IS) per chromosome and samples\n",
    "- pseudo common insertion site (pCIS) is found using a graph based proximity approach of the IS\n",
    "  - chromosome is the actual graph object\n",
    "  - an IS is represented as a node in the graph\n",
    "  - pCIS is a distinct subgraph within the chromosome graph\n",
    "- pCIS -> CIS based on some sort of statistic\n",
    "  - currently using LFC or binomial for significance, not any graph based form of significance\n",
    "\n",
    "# IS significance\n",
    "\n",
    "### not read normalized - set a threshold of read\n",
    "\n",
    "- less than threshold, then no IS event (count of 1 is implicitely used)\n",
    "- more than threshold, it is an IS event\n",
    "- start with threshold of 10 reads, but results would likely change based on this\n",
    "\n",
    "### read normalized - use a penetrance(like) score\n",
    "\n",
    "- determine the strength of the IS\n",
    "- add 1 pseudo count divided by read depth or the reads per million mapped to a site\n",
    "- read depth normalization is done per sample and per chromosome\n",
    "- divide read counts at IS by the total reads on the chromosome\n",
    "- look into outliers\n",
    "- So for normalization, I can think of two ways: counts per million (CPM) and transposon copy number (TCN)\n",
    "  - CPM: scale counts based on library read counts (total reads in IRR/IRL per sample)\n",
    "  - TCN: scale counts based on transposon read counts (total reads in both IRR and IRL per sample)\n",
    "- \n",
    "- TODO: make plots and slides to capture the above things\n",
    "  - avg total read count per chromosome across all samples and controls\n",
    "  - plot the normalized values and replot with the read sum. It should have approx the same read depth\n",
    "  - read count normalized per site\n",
    "\n",
    "# Statistics\n",
    "hypergeometric/fisher's exact test\n",
    "- choose threshold. Are there more or less than this?\n",
    "- do this per sample in a pCIS for how many samples met this threshold\n",
    "- use total valid samples. How many insertions needed to be valid? defualt is 0 meaning does a sample have any reads in a pCIS\n",
    "- gives a binary profile for cases and controls that is then used in fisher's exact test\n",
    "- Easy to then test different thresholds\n",
    "\n",
    "quantitative\n",
    "- sum read depth normalized counts per sample then use rank sums\n",
    "- use one sided test (why this?)\n",
    "\n",
    "global\n",
    "- how many CIS's in each group\n",
    "\n",
    "Misc\n",
    "- could try testing right and left sum ranks versus spleen\n",
    "- use fdr cause we are testing a certain amount of pCIS's\n",
    "- can stick with union of two pCIS's range. Then get into the interesting genomic features for the identified CIS's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cis_networks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import networkx as nx\n",
    "\n",
    "module_path = \"/home/fisch872/mat/projects/Laura-SB-Analysis/NetCIS/\"\n",
    "sys.path.append(module_path)\n",
    "from netcis import cis_networks as cn\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "args = {\n",
    "    # \"output_prefix\" : \"/project/cs-myers/MathewF/projects/Laura-SB-Analysis/2023-SB-screen/output/ACF_SCF/GRCm39/results\",\n",
    "    \"output_prefix\": \"/project/cs-myers/MathewF/projects/Laura-SB-Analysis/2020_SB-output/GRCm39/results\",\n",
    "    \"verbose\": 0,\n",
    "    \"threshold\": 50000,\n",
    "    \"njobs\": 1,\n",
    "    }\n",
    "\n",
    "args[\"insertion_dir\"] = Path(args[\"output_prefix\"] + \"-insertions\")\n",
    "args[\"depth_dir\"] = Path(args[\"output_prefix\"] + \"-insertions-depth\")\n",
    "args[\"output\"] = Path(args[\"output_prefix\"] + \"-graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:01, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:02, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:04,  4.80it/s]\n"
     ]
    }
   ],
   "source": [
    "reload(cn)\n",
    "\n",
    "# new way of doing things\n",
    "insertion_list = [ pd.read_csv(file, sep=\"\\t\") for file in args[\"depth_dir\"].iterdir() ]\n",
    "inserts_df = pd.concat(insertion_list, ignore_index=True)\n",
    "inserts_df.insert(4, \"counts_irr\", np.where(inserts_df['library'] == 'IRR', 1, 0))\n",
    "inserts_df.insert(5, \"counts_irl\", np.where(inserts_df['library'] == 'IRL', 1, 0))\n",
    "# display(inserts_df)\n",
    "\n",
    "def create_graph(iter_args):\n",
    "    chrom_df, save_dir, threshold, verbose = iter_args\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    cols = [\"CPM\", \"counts_irr\", \"counts_irl\"]\n",
    "    tmp_group = chrom_df.groupby(by=['chr', 'pos'], sort=False, as_index=False, dropna=False)\n",
    "    insertion_nodes_df = tmp_group[cols].sum()\n",
    "    insertion_nodes_df.insert(2, \"counts\", tmp_group['count'].count().pop('count'))\n",
    "\n",
    "    # add in info about which samples are in each insertion site\n",
    "    tmp_samples = chrom_df.groupby(by=['chr', 'pos'], sort=False, as_index=False, dropna=False)[\"sampleID\"].apply(lambda x: x.unique())\n",
    "    if tmp_samples.size == 0:\n",
    "        insertion_nodes_df[\"n_samples\"] = 0\n",
    "        insertion_nodes_df[\"sample_IDs\"] = []\n",
    "    else:\n",
    "        insertion_nodes_df.insert(6, \"n_samples\", tmp_samples[\"sampleID\"].apply(lambda x: len(x)))\n",
    "        insertion_nodes_df.insert(6, \"sample_IDs\", tmp_samples[\"sampleID\"].apply(lambda x: list(x)).to_list())\n",
    "\n",
    "    # add nodes and edges to graph\n",
    "    G.add_nodes_from(cn.add_nodes(insertion_nodes_df))\n",
    "    G.add_edges_from(cn.find_edges(G.nodes(), threshold))\n",
    "    \n",
    "    if verbose > 1:\n",
    "        cn.graph_properties(G)\n",
    "\n",
    "    # save the graph\n",
    "    nx.write_gml(G, save_dir / \"G.gml\")\n",
    "    \n",
    "    # save subgraphs from graph\n",
    "    subgraphs_by_nodes = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "    subgraphs = [ G.subgraph(x) for x in subgraphs_by_nodes ]\n",
    "    with open(save_dir / \"subgraphs.pickle\", \"wb\") as f:\n",
    "        pickle.dump(subgraphs, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "chrom_list = np.unique(inserts_df[\"chr\"].to_numpy())\n",
    "treatment_list = inserts_df[\"treatment\"].unique()\n",
    "\n",
    "# total unique samples across all treatments\n",
    "total_samples = inserts_df[\"sampleID\"].unique().shape[0]\n",
    "metadata = {\"total\": total_samples}\n",
    "\n",
    "for treatment in treatment_list:\n",
    "    print(treatment)\n",
    "    # prepare output\n",
    "    out_dir = args['output'] / treatment\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    treatment_df = inserts_df[inserts_df[\"treatment\"] == treatment]\n",
    "    metadata[treatment] = treatment_df[\"sampleID\"].unique().shape[0]\n",
    "    \n",
    "    # don't allow more jobs than there are chromosomes\n",
    "    jobs = args[\"njobs\"]\n",
    "    num_chr = len(chrom_list)\n",
    "    if num_chr < jobs:\n",
    "        print(f\"Reducing number of jobs from {jobs} to {num_chr}, since there are only {num_chr} chromosomes present.\")\n",
    "        jobs = len(chrom_list)\n",
    "        \n",
    "    # construct CIS network per chromosome for treatment insertion\n",
    "    iter_gen = cn.create_graph_generator(chrom_list, treatment_df, out_dir, args)\n",
    "    iter_gen = tqdm(iter_gen)\n",
    "    with Pool(jobs) as p:\n",
    "        for _ in p.imap_unordered(create_graph, iter_gen):\n",
    "            pass\n",
    "        p.close()\n",
    "        \n",
    "# save sample numbers as meta data for network analysis\n",
    "samples, counts = zip(*metadata.items())\n",
    "meta_df = pd.DataFrame({\"samples\": samples, \"counts\": counts})\n",
    "meta_df.to_csv(args['output'].parent / \"samples_with_insertions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'netcis.network_analysis' from '/home/fisch872/mat/projects/Laura-SB-Analysis/NetCIS/netcis/network_analysis.py'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn.objects as so\n",
    "from seaborn import axes_style\n",
    "import networkx as nx\n",
    "from scipy.stats import binomtest, ranksums, fisher_exact, boschloo_exact\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import display\n",
    "from importlib import reload\n",
    "\n",
    "module_path = \"/home/fisch872/mat/projects/Laura-SB-Analysis/NetCIS/\"\n",
    "sys.path.append(module_path)\n",
    "from netcis import network_analysis as na\n",
    "reload(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdata = Path(\"/project/cs-myers/MathewF/projects/Laura-SB-Analysis/2023-SB-screen/ref_data/GRCm39\")\n",
    "\n",
    "args = {\n",
    "    # \"output_prefix\": \"/project/cs-myers/MathewF/projects/Laura-SB-Analysis/2023-SB-screen/output/GRCm39/results\", \n",
    "    \"output_prefix\": \"/project/cs-myers/MathewF/projects/Laura-SB-Analysis/2020_SB-output/GRCm39/results\", \n",
    "    \"ta_dir\": refdata / \"ta_files\",\n",
    "    \"gene_annot\": refdata / \"MRK_List2.rpt\",\n",
    "    \"ta_error\": 5,\n",
    "    \"pval_threshold\": 0.05,\n",
    "    \"verbose\": 1,\n",
    "    \"case\": \"LT\",  #    CAR     ACF    LT RT\n",
    "    \"control\": \"S\",  # NoCAR   SCF    S \n",
    "    \"njobs\": 22,\n",
    "}\n",
    "\n",
    "graph_dir = Path(args[\"output_prefix\"] + \"-graphs/\")\n",
    "args[\"graph_dir\"] = graph_dir\n",
    "output = Path(args[\"output_prefix\"] + \"-analysis-new\")\n",
    "output.mkdir(exist_ok=True)\n",
    "\n",
    "ta_dir = args[\"ta_dir\"]\n",
    "gene_annot = args[\"gene_annot\"]\n",
    "ta_error = args[\"ta_error\"]\n",
    "pval_threshold = args[\"pval_threshold\"]\n",
    "verbose = args[\"verbose\"]\n",
    "case = args[\"case\"]\n",
    "control = args[\"control\"]\n",
    "njobs = args[\"njobs\"]\n",
    "\n",
    "output_res = output / f\"{case}-{control}\"\n",
    "output_res.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrM', 'chrX', 'chrY']\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "annot_df = pd.read_csv(gene_annot, sep=\"\\t\")\n",
    "annot_df = annot_df[pd.notna(annot_df[\"genome coordinate start\"])].drop(\"Status\", axis=1)\n",
    "annot_df[\"chrom\"] = annot_df[\"Chr\"].apply(lambda x: f\"chr{x}\")\n",
    "annot_df = annot_df.sort_values([\"chrom\"]).reset_index(drop=True)\n",
    "\n",
    "bed_files = {file.name.split(\".\")[0]: file for file in args[\"ta_dir\"].iterdir()}\n",
    "\n",
    "chroms = sorted([ chrom.name for chrom in (graph_dir / case).iterdir() ])\n",
    "print(chroms)\n",
    "print(len(chroms))\n",
    "\n",
    "# don't allow more jobs than there are chromosomes\n",
    "jobs = args[\"njobs\"]\n",
    "num_chr = len(chroms)\n",
    "if num_chr < jobs:\n",
    "    print(f\"Reducing number of jobs from {jobs} to {num_chr}, since there are only {num_chr} chromosomes present.\")\n",
    "    jobs = len(chroms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrom\tCIS/pCIS\n",
      "chrM\t1/1\n",
      "chr19\t141/197\n",
      "chrY\t105/191\n",
      "chr17\t262/350\n",
      "chr18\t222/323\n",
      "chr16\t288/403\n",
      "chr15\t308/420\n",
      "chr11\t326/436\n",
      "chr13\t304/431\n",
      "chr8\t347/481\n",
      "chr14\t357/492\n",
      "chr10\t372/511\n",
      "chr12\t369/495\n",
      "chr7\t415/546\n",
      "chr6\t409/567\n",
      "chr5\t424/559\n",
      "chr3\t442/639\n",
      "chr9\t452/585\n",
      "chrX\t500/768\n",
      "chr2\t487/671\n",
      "chr4\t781/952\n",
      "chr1\t1018/1212\n"
     ]
    }
   ],
   "source": [
    "# iter_args = tqdm([ (chrom, annot_df[annot_df[\"chrom\"] == chrom], bed_files[chrom], args) for chrom in chroms ])\n",
    "reload(na)\n",
    "iter_args = [ (chrom, annot_df[annot_df[\"chrom\"] == chrom], bed_files[chrom], args) for chrom in chroms ]\n",
    "print(\"chrom\\tCIS/pCIS\")\n",
    "with Pool(args[\"njobs\"]) as p:\n",
    "    res_dict_list = [ x for x in p.imap_unordered(na.chrom_analysis, iter_args) ]\n",
    "    \n",
    "# join chromosomes results together  \n",
    "IS_list = []\n",
    "pCIS_list = []\n",
    "CIS_list = []\n",
    "for res_dict in res_dict_list:\n",
    "    IS_list.append(res_dict[\"is\"])\n",
    "    pCIS_list.append(res_dict[\"pcis\"])\n",
    "    CIS_list.append(res_dict[\"cis\"])\n",
    "\n",
    "IS_df = pd.concat(IS_list, ignore_index=True)\n",
    "pCIS_df = pd.concat(pCIS_list, ignore_index=True)\n",
    "CIS_df = pd.concat(CIS_list, ignore_index=True)\n",
    "\n",
    "# save results\n",
    "IS_df.to_csv(output_res / \"IS.tsv\", sep=\"\\t\", index=False)\n",
    "pCIS_df.to_csv(output_res / \"pCIS.tsv\", sep=\"\\t\", index=False)\n",
    "CIS_df.to_csv(output_res / \"CIS.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test individual chrom, minimal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\n"
     ]
    }
   ],
   "source": [
    "iter_args = [ (chrom, annot_df[annot_df[\"chrom\"] == chrom], bed_files[chrom], args) for chrom in chroms ]\n",
    "# with Pool(args[\"njobs\"]) as p:\n",
    "#     res_dict_list = [ x for x in p.imap_unordered(chrom_analysis, iter_args) ]\n",
    "chrom, annot_chrom_df, chrom_bed_file, args = iter_args[0]\n",
    "print(chrom)\n",
    "\n",
    "\n",
    "graph_dir = args[\"graph_dir\"]\n",
    "case = args[\"case\"]\n",
    "control = args[\"control\"]\n",
    "ta_error = args[\"ta_error\"]\n",
    "pval_threshold = args[\"pval_threshold\"]\n",
    "verbose = args[\"verbose\"]\n",
    "gene_expander = 50000  # TODO: add to input args\n",
    "\n",
    "\n",
    "# get bed chromosome file to find positions of TAs\n",
    "bed_chrom_df = pd.read_csv(chrom_bed_file, sep=\"\\t\", header=None)\n",
    "\n",
    "# get basic stats on case chromosome subgraphs \n",
    "with open(graph_dir / case / chrom / \"subgraphs.pickle\", 'rb') as f:\n",
    "    case_chrom_subgraphs = pickle.load(f)\n",
    "case_chrom_df = na.get_subgraph_stats(case_chrom_subgraphs, case, chrom, bed_chrom_df, ta_error)\n",
    "    \n",
    "# get basic stats on control chromosome subgraphs \n",
    "with open(graph_dir / control / chrom / \"subgraphs.pickle\", 'rb') as f:\n",
    "    control_chrom_subgraphs = pickle.load(f)\n",
    "control_chrom_df = na.get_subgraph_stats(control_chrom_subgraphs, control, chrom, bed_chrom_df, ta_error)\n",
    "\n",
    "\n",
    "# get total samples for case and controls\n",
    "# double list comprehension https://stackoverflow.com/questions/17657720/python-list-comprehension-double-for\n",
    "# but using a set to remove duplicates\n",
    "case_samples = { x for y in case_chrom_df[\"sample_IDs\"] for x in y }\n",
    "control_samples = { x for y in control_chrom_df[\"sample_IDs\"] for x in y }\n",
    "num_cases = len(case_samples)\n",
    "num_controls = len(control_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the overlapping pCIS between case and control subgraphs\n",
    "reload(na)\n",
    "overlap_df = na.pcis_overlaps(case_chrom_df, control_chrom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare pcis\n",
    "IS_df_list = []\n",
    "pCIS_df_list = []\n",
    "\n",
    "for overlap in overlap_df.itertuples():\n",
    "    # get normalized read counts (CPM) for each pCIS\n",
    "    case_ind = overlap.case\n",
    "    control_ind = overlap.control\n",
    "    \n",
    "    # if just case \n",
    "    if control_ind is None or np.isnan(control_ind):\n",
    "        case_G = case_chrom_subgraphs[case_ind]\n",
    "        case_pos = [ case_G.nodes[node]['position'] for node in case_G.nodes ]\n",
    "        tmp_case = pd.DataFrame([ {\"case_count\": case_G.nodes[node]['CPM']} for node in case_G.nodes ], index=case_pos)\n",
    "        tmp_case[\"case_index\"] = case_ind\n",
    "        \n",
    "        tmp = tmp_case\n",
    "        tmp[\"control_count\"] = 0.0\n",
    "        tmp[\"control_index\"] = np.nan\n",
    "        \n",
    "        num_case_samples = len({ x for y in [ case_G.nodes[node][\"sample_IDs\"] for node in case_G.nodes ] for x in y })\n",
    "        num_control_samples = 0\n",
    "        \n",
    "        case_pos_min = min(case_pos)\n",
    "        case_pos_max = max(case_pos)\n",
    "        control_pos_min = None\n",
    "        control_pos_max = None\n",
    "        \n",
    "        case_IS = len(tmp)\n",
    "        control_IS = 0\n",
    "        \n",
    "    # if just control\n",
    "    elif case_ind is None or np.isnan(case_ind):\n",
    "        control_G = control_chrom_subgraphs[control_ind]\n",
    "        control_pos = [ control_G.nodes[node]['position'] for node in control_G.nodes ]\n",
    "        tmp_control = pd.DataFrame([ {\"control_count\": control_G.nodes[node]['CPM']} for node in control_G.nodes ], index=control_pos)\n",
    "        tmp_control[\"control_index\"] = control_ind\n",
    "        \n",
    "        tmp = tmp_control\n",
    "        tmp[\"case_count\"] = 0.0\n",
    "        tmp[\"case_index\"] = np.nan\n",
    "        \n",
    "        num_case_samples = 0\n",
    "        num_control_samples = len({ x for y in [ control_G.nodes[node][\"sample_IDs\"] for node in control_G.nodes ] for x in y })\n",
    "    \n",
    "        case_pos_min = None\n",
    "        case_pos_max = None\n",
    "        control_pos_min = min(control_pos)\n",
    "        control_pos_max = max(control_pos)\n",
    "\n",
    "        case_IS = 0\n",
    "        control_IS = len(tmp)\n",
    "        \n",
    "    # if one case and one control\n",
    "    elif type(case_ind) is not list and type(control_ind) is not list:\n",
    "        case_G = case_chrom_subgraphs[case_ind]\n",
    "        case_pos = [ case_G.nodes[node]['position'] for node in case_G.nodes ]\n",
    "        tmp_case = pd.DataFrame([ {\"case_count\": case_G.nodes[node]['CPM']} for node in case_G.nodes ], index=case_pos)\n",
    "        tmp[\"case_index\"] = case_ind\n",
    "        \n",
    "        control_G = control_chrom_subgraphs[control_ind]\n",
    "        control_pos = [ control_G.nodes[node]['position'] for node in control_G.nodes ]\n",
    "        tmp_control = pd.DataFrame([ {\"control_count\": control_G.nodes[node]['CPM']} for node in control_G.nodes ], index=control_pos)\n",
    "        tmp[\"control_index\"] = control_ind\n",
    "        \n",
    "        tmp = tmp_case.join(tmp_control, how=\"outer\")\n",
    "        \n",
    "        num_case_samples = len({ x for y in [ case_G.nodes[node][\"sample_IDs\"] for node in case_G.nodes ] for x in y })\n",
    "        num_control_samples = len({ x for y in [ control_G.nodes[node][\"sample_IDs\"] for node in control_G.nodes ] for x in y })\n",
    "        \n",
    "        case_pos_min = min(case_pos)\n",
    "        case_pos_max = max(case_pos)\n",
    "        control_pos_min = min(control_pos)\n",
    "        control_pos_max = max(control_pos)\n",
    "        \n",
    "        case_IS = len(tmp_case)\n",
    "        control_IS = len(tmp_control)\n",
    "        \n",
    "    # if multiple case \n",
    "    elif type(case_ind) is list:\n",
    "        # get single control\n",
    "        control_G = control_chrom_subgraphs[control_ind]\n",
    "        control_pos = [ control_G.nodes[node]['position'] for node in control_G.nodes ]\n",
    "        tmp_control = pd.DataFrame([ {\"control_count\": control_G.nodes[node]['CPM']} for node in control_G.nodes ], index=control_pos)\n",
    "        tmp_control[\"control_index\"] = control_ind\n",
    "        \n",
    "        case_samples = set()\n",
    "        num_control_samples = len({ x for y in [ control_G.nodes[node][\"sample_IDs\"] for node in control_G.nodes ] for x in y })\n",
    "        \n",
    "        # get multiple cases\n",
    "        tmp_case_list = []\n",
    "        tmp_case_pos = []\n",
    "        for case_index in case_ind:\n",
    "            case_G = case_chrom_subgraphs[case_index]\n",
    "            case_position = [ case_G.nodes[node]['position'] for node in case_G.nodes ]\n",
    "            tmp_case_pos.extend(case_position)\n",
    "            tmp_case = pd.DataFrame([ {\"case_count\": case_G.nodes[node]['CPM']} for node in case_G.nodes ], index=case_position)\n",
    "            tmp_case[\"case_index\"] = int(case_index)\n",
    "            tmp_case_list.append(tmp_case)\n",
    "            case_samples = case_samples.union({ x for y in [ case_G.nodes[node][\"sample_IDs\"] for node in case_G.nodes ] for x in y })\n",
    "        num_case_samples = len(case_samples)\n",
    "        tmp_cases = pd.concat(tmp_case_list, axis=0)\n",
    "        tmp = tmp_control.join(tmp_cases, how=\"outer\")\n",
    "        \n",
    "        case_pos_min = min(tmp_case_pos)\n",
    "        case_pos_max = max(tmp_case_pos)\n",
    "        control_pos_min = min(control_pos)\n",
    "        control_pos_max = max(control_pos)\n",
    "\n",
    "        case_IS = len(tmp_cases)\n",
    "        control_IS = len(tmp_control)\n",
    "        \n",
    "    # if mulitple control\n",
    "    elif type(control_ind) is list:\n",
    "        # get single case\n",
    "        case_G = case_chrom_subgraphs[case_ind]\n",
    "        case_pos = [ case_G.nodes[node]['position'] for node in case_G.nodes ]\n",
    "        tmp_case = pd.DataFrame([ {\"case_count\": case_G.nodes[node]['CPM']} for node in case_G.nodes ], index=case_pos)\n",
    "        tmp_case[\"case_index\"] = case_ind\n",
    "\n",
    "        num_case_samples = len({ x for y in [ case_G.nodes[node][\"sample_IDs\"] for node in case_G.nodes ] for x in y })\n",
    "        control_samples = set()\n",
    "        \n",
    "        # get multiple controls\n",
    "        tmp_control_list = []\n",
    "        tmp_control_pos = []\n",
    "        for control_index in control_ind:\n",
    "            control_G = control_chrom_subgraphs[control_index]\n",
    "            control_pos = [ control_G.nodes[node]['position'] for node in control_G.nodes ]\n",
    "            tmp_control_pos.extend(control_pos)\n",
    "            tmp_control = pd.DataFrame([ {\"control_count\": control_G.nodes[node]['CPM']} for node in control_G.nodes ], index=control_pos)\n",
    "            tmp_control[\"control_index\"] = int(control_index)\n",
    "            tmp_control_list.append(tmp_control)\n",
    "            control_samples = control_samples.union({ x for y in [ control_G.nodes[node][\"sample_IDs\"] for node in control_G.nodes ] for x in y })\n",
    "        num_control_samples = len(control_samples)\n",
    "        tmp_controls = pd.concat(tmp_control_list, axis=0)\n",
    "        tmp = tmp_case.join(tmp_controls, how=\"outer\")\n",
    "        \n",
    "        case_pos_min = min(case_pos)\n",
    "        case_pos_max = max(case_pos)\n",
    "        control_pos_min = min(tmp_control_pos)\n",
    "        control_pos_max = max(tmp_control_pos)\n",
    "\n",
    "        case_IS = len(tmp_cases)\n",
    "        control_IS = len(tmp_control)\n",
    "        \n",
    "    else:\n",
    "        print(overlap)\n",
    "        print(\"this shouldn't happen\")\n",
    "    \n",
    "    # only fillna in case_count and control_count\n",
    "    tmp[\"case_count\"] = tmp[\"case_count\"].fillna(0.0)\n",
    "    tmp[\"control_count\"] = tmp[\"control_count\"].fillna(0.0)\n",
    "    tmp = tmp.reset_index(drop=False).rename(columns={\"index\": \"pos\"})\n",
    "\n",
    "\n",
    "    # run stats for each pCIS\n",
    "    # NOTE: binomtest takes only integeres, so I'm converting the normalized read counts to the closest integers\n",
    "    # get stats per TA site (only count is used)\n",
    "    # used pseudo count of 1 for log fold change, and so I wanted to show the difference in binomial test and significance with this\n",
    "    tmp[\"target_binom_pval\"] = tmp.apply(lambda x: binomtest( int(x[\"case_count\"]) + 1, int(x[\"case_count\"] + x[\"control_count\"]) + 1 ).pvalue, axis=1)\n",
    "    tmp[\"target_binom_sig\"] = tmp[\"target_binom_pval\"] < 0.05\n",
    "    tmp[\"LFC\"] = tmp.apply(lambda x: np.log2((x[\"case_count\"] + 1) / (x[\"control_count\"] + 1)), axis=1)\n",
    "\n",
    "    rs = ranksums(tmp[\"case_count\"], tmp[\"control_count\"]).pvalue\n",
    "    binom = binomtest(int(tmp[\"case_count\"].sum()) + 1, int(tmp[\"case_count\"].sum() + tmp[\"control_count\"].sum()) + 1, 0.5).pvalue\n",
    "    \n",
    "    total_IS = len(tmp)\n",
    "    sig_IS = tmp[\"target_binom_sig\"].sum()\n",
    "    \n",
    "    # contingency table = [[a, b], [c, d]]\n",
    "    #            in pCIS   not in pCIS\n",
    "    # target        a           b\n",
    "    # reference     c           d\n",
    "    a = num_case_samples\n",
    "    b = num_cases - num_case_samples\n",
    "    c = num_control_samples\n",
    "    d = num_controls - num_control_samples\n",
    "    if a < 0 or b < 0 or c < 0 or d < 0:\n",
    "        print(chrom)\n",
    "        print(a, b, num_cases)\n",
    "        print(c, d, num_controls)\n",
    "    fi = fisher_exact([[a, b], [c, d]]).pvalue\n",
    "    \n",
    "    tmp2 = {\n",
    "        \"case_index\": case_ind,\n",
    "        \"case_pos_min\": case_pos_min,\n",
    "        \"case_pos_max\": case_pos_max,\n",
    "        \"control_index\": control_ind,\n",
    "        \"control_pos_min\": control_pos_min,\n",
    "        \"control_pos_max\": control_pos_max,\n",
    "        \n",
    "        \"ranksums\": rs,\n",
    "        \"binomial\": binom,\n",
    "        \"fishers_exact\": fi,\n",
    "    \n",
    "        \"case_num_samples\": num_case_samples,\n",
    "        \"control_num_samples\": num_control_samples,\n",
    "        \n",
    "        \"total_IS\": total_IS,\n",
    "        \"case_IS\": case_IS,\n",
    "        \"control_IS\": control_IS,\n",
    "        \"case_total_read_count\": tmp[\"case_count\"].sum(),\n",
    "        \"control_total_read_count\": tmp[\"control_count\"].sum(),\n",
    "        }\n",
    "    \n",
    "    IS_df_list.append(tmp)\n",
    "    pCIS_df_list.append(tmp2)\n",
    "    \n",
    "IS_df = pd.concat(IS_df_list, ignore_index=True)\n",
    "IS_df[\"case\"] = case\n",
    "IS_df[\"control\"] = control\n",
    "IS_df[\"chrom\"] = chrom\n",
    "\n",
    "pCIS_df = pd.DataFrame(pCIS_df_list)\n",
    "pCIS_df[\"case\"] = case\n",
    "pCIS_df[\"control\"] = control\n",
    "pCIS_df[\"chrom\"] = chrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_index</th>\n",
       "      <th>case_pos_min</th>\n",
       "      <th>case_pos_max</th>\n",
       "      <th>control_index</th>\n",
       "      <th>control_pos_min</th>\n",
       "      <th>control_pos_max</th>\n",
       "      <th>ranksums</th>\n",
       "      <th>binomial</th>\n",
       "      <th>fishers_exact</th>\n",
       "      <th>case_num_samples</th>\n",
       "      <th>control_num_samples</th>\n",
       "      <th>total_IS</th>\n",
       "      <th>case_IS</th>\n",
       "      <th>control_IS</th>\n",
       "      <th>case_total_read_count</th>\n",
       "      <th>control_total_read_count</th>\n",
       "      <th>case</th>\n",
       "      <th>control</th>\n",
       "      <th>chrom</th>\n",
       "      <th>genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>86858017.0</td>\n",
       "      <td>86858024.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.953461e-02</td>\n",
       "      <td>3.889385e-62</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>204.786894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Aak1, wa1l, Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211</td>\n",
       "      <td>86976665.0</td>\n",
       "      <td>86976665.0</td>\n",
       "      <td>3.173105e-01</td>\n",
       "      <td>7.801456e-131</td>\n",
       "      <td>0.412903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>441.270860</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Aak1, wa1l, Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1</td>\n",
       "      <td>86910505.0</td>\n",
       "      <td>86911207.0</td>\n",
       "      <td>1</td>\n",
       "      <td>86886567.0</td>\n",
       "      <td>86910900.0</td>\n",
       "      <td>3.931046e-10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.355551</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>108</td>\n",
       "      <td>101</td>\n",
       "      <td>77</td>\n",
       "      <td>151431.857664</td>\n",
       "      <td>23456.878311</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Aak1, wa1l, Sndy1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    case_index  case_pos_min  case_pos_max control_index  control_pos_min  \\\n",
       "5           14    86858017.0    86858024.0          None              NaN   \n",
       "354       None           NaN           NaN           211       86976665.0   \n",
       "534          1    86910505.0    86911207.0             1       86886567.0   \n",
       "\n",
       "     control_pos_max      ranksums       binomial  fishers_exact  \\\n",
       "5                NaN  4.953461e-02   3.889385e-62       1.000000   \n",
       "354       86976665.0  3.173105e-01  7.801456e-131       0.412903   \n",
       "534       86910900.0  3.931046e-10   0.000000e+00       0.355551   \n",
       "\n",
       "     case_num_samples  control_num_samples  total_IS  case_IS  control_IS  \\\n",
       "5                   1                    0         3        3           0   \n",
       "354                 0                    1         1        0           1   \n",
       "534                64                   50       108      101          77   \n",
       "\n",
       "     case_total_read_count  control_total_read_count case control chrom  \\\n",
       "5               204.786894                  0.000000   LT       S  chr6   \n",
       "354               0.000000                441.270860   LT       S  chr6   \n",
       "534          151431.857664              23456.878311   LT       S  chr6   \n",
       "\n",
       "                   genes  \n",
       "5    [Aak1, wa1l, Sndy1]  \n",
       "354  [Aak1, wa1l, Sndy1]  \n",
       "534  [Aak1, wa1l, Sndy1]  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get genes for each pCIS\n",
    "\n",
    "\n",
    "# gene_expander = 50000\n",
    "gene_expander = 0\n",
    "\n",
    "# trim down annotation dataframe to just gene\n",
    "annot_chrom_genes = annot_chrom_df[annot_chrom_df[\"Marker Type\"] == \"Gene\"]\n",
    "gene_names = annot_chrom_genes[\"Marker Symbol\"].to_numpy()\n",
    "\n",
    "pos_min = pCIS_df[[\"case_pos_min\", \"control_pos_min\"]].min(axis=1).to_numpy().reshape(-1, 1)\n",
    "pos_max = pCIS_df[[\"case_pos_max\", \"control_pos_max\"]].max(axis=1).to_numpy().reshape(-1, 1)\n",
    "gene_start = (annot_chrom_genes[\"genome coordinate start\"] - gene_expander).to_numpy().reshape(1, -1)\n",
    "gene_end = (annot_chrom_genes[\"genome coordinate end\"] + gene_expander).to_numpy().reshape(1, -1)\n",
    "tmp = (pos_min <= gene_end) & (pos_max >= gene_start)\n",
    "\n",
    "pCIS_df[\"genes\"] = [ list(gene_names[tmp[i]]) for i in range(tmp.shape[0]) ]\n",
    "\n",
    "\n",
    "# search for a gene\n",
    "gene_search = \"Aak1\"\n",
    "pCIS_df[pCIS_df[\"genes\"].apply(lambda x: gene_search in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_index</th>\n",
       "      <th>case_pos_min</th>\n",
       "      <th>case_pos_max</th>\n",
       "      <th>control_index</th>\n",
       "      <th>control_pos_min</th>\n",
       "      <th>control_pos_max</th>\n",
       "      <th>ranksums</th>\n",
       "      <th>binomial</th>\n",
       "      <th>fishers_exact</th>\n",
       "      <th>case_num_samples</th>\n",
       "      <th>control_num_samples</th>\n",
       "      <th>total_IS</th>\n",
       "      <th>case_IS</th>\n",
       "      <th>control_IS</th>\n",
       "      <th>case_total_read_count</th>\n",
       "      <th>control_total_read_count</th>\n",
       "      <th>case</th>\n",
       "      <th>control</th>\n",
       "      <th>chrom</th>\n",
       "      <th>genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>133492835.0</td>\n",
       "      <td>133505740.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.745119e-03</td>\n",
       "      <td>1.535690e-238</td>\n",
       "      <td>0.021223</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>790.045473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>29174318.0</td>\n",
       "      <td>29174323.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.092134e-02</td>\n",
       "      <td>2.980232e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25.663399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Prrt4, tint]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>30608702.0</td>\n",
       "      <td>30608706.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.092134e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3059.975520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Gm31453, Hdp1, tint]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>16307995.0</td>\n",
       "      <td>16350128.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.092134e-02</td>\n",
       "      <td>9.055679e-72</td>\n",
       "      <td>0.512023</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>236.923721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>90544038.0</td>\n",
       "      <td>90544042.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.092134e-02</td>\n",
       "      <td>6.077163e-64</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>210.737582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Aldh1l1, wa1l, Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>125</td>\n",
       "      <td>66218819.0</td>\n",
       "      <td>66218819.0</td>\n",
       "      <td>94</td>\n",
       "      <td>66218819.0</td>\n",
       "      <td>66225910.0</td>\n",
       "      <td>4.385780e-01</td>\n",
       "      <td>7.366511e-06</td>\n",
       "      <td>0.306937</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28.026906</td>\n",
       "      <td>75.798475</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Gm36408, Hdp1, Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>183</td>\n",
       "      <td>103626139.0</td>\n",
       "      <td>103626139.0</td>\n",
       "      <td>3</td>\n",
       "      <td>103626021.0</td>\n",
       "      <td>103647633.0</td>\n",
       "      <td>1.333961e-11</td>\n",
       "      <td>3.789431e-279</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2.593428</td>\n",
       "      <td>950.402410</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Chl1, ssl, Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>184</td>\n",
       "      <td>111438186.0</td>\n",
       "      <td>111438186.0</td>\n",
       "      <td>38</td>\n",
       "      <td>111349308.0</td>\n",
       "      <td>111438186.0</td>\n",
       "      <td>8.326452e-02</td>\n",
       "      <td>1.548895e-09</td>\n",
       "      <td>0.082194</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10.606703</td>\n",
       "      <td>61.147122</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Grm7, ssl, Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>[3, 21]</td>\n",
       "      <td>133573805.0</td>\n",
       "      <td>133676524.0</td>\n",
       "      <td>5</td>\n",
       "      <td>133553711.0</td>\n",
       "      <td>133676524.0</td>\n",
       "      <td>8.419395e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.120192</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>5597.302232</td>\n",
       "      <td>641.691134</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>13</td>\n",
       "      <td>45396970.0</td>\n",
       "      <td>45459629.0</td>\n",
       "      <td>[11, 238]</td>\n",
       "      <td>45387412.0</td>\n",
       "      <td>45457323.0</td>\n",
       "      <td>8.183746e-02</td>\n",
       "      <td>2.927402e-04</td>\n",
       "      <td>0.691459</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>38.296036</td>\n",
       "      <td>79.610095</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Gm43880, Hdp1, Cntnap2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    case_index  case_pos_min  case_pos_max control_index  control_pos_min  \\\n",
       "0            6   133492835.0   133505740.0          None              NaN   \n",
       "1            8    29174318.0    29174323.0          None              NaN   \n",
       "2            9    30608702.0    30608706.0          None              NaN   \n",
       "3           10    16307995.0    16350128.0          None              NaN   \n",
       "4           11    90544038.0    90544042.0          None              NaN   \n",
       "..         ...           ...           ...           ...              ...   \n",
       "559        125    66218819.0    66218819.0            94       66218819.0   \n",
       "563        183   103626139.0   103626139.0             3      103626021.0   \n",
       "564        184   111438186.0   111438186.0            38      111349308.0   \n",
       "565    [3, 21]   133573805.0   133676524.0             5      133553711.0   \n",
       "566         13    45396970.0    45459629.0     [11, 238]       45387412.0   \n",
       "\n",
       "     control_pos_max      ranksums       binomial  fishers_exact  \\\n",
       "0                NaN  1.745119e-03  1.535690e-238       0.021223   \n",
       "1                NaN  2.092134e-02   2.980232e-08       1.000000   \n",
       "2                NaN  2.092134e-02   0.000000e+00       1.000000   \n",
       "3                NaN  2.092134e-02   9.055679e-72       0.512023   \n",
       "4                NaN  2.092134e-02   6.077163e-64       1.000000   \n",
       "..               ...           ...            ...            ...   \n",
       "559       66225910.0  4.385780e-01   7.366511e-06       0.306937   \n",
       "563      103647633.0  1.333961e-11  3.789431e-279       0.000017   \n",
       "564      111438186.0  8.326452e-02   1.548895e-09       0.082194   \n",
       "565      133676524.0  8.419395e-02   0.000000e+00       0.120192   \n",
       "566       45457323.0  8.183746e-02   2.927402e-04       0.691459   \n",
       "\n",
       "     case_num_samples  control_num_samples  total_IS  case_IS  control_IS  \\\n",
       "0                   8                    0         7        7           0   \n",
       "1                   1                    0         4        4           0   \n",
       "2                   1                    0         4        4           0   \n",
       "3                   2                    0         4        4           0   \n",
       "4                   1                    0         4        4           0   \n",
       "..                ...                  ...       ...      ...         ...   \n",
       "559                 1                    3         2        1           2   \n",
       "563                 1                   14        33        1          32   \n",
       "564                 1                    5         4        1           4   \n",
       "565                24                   10        25       16          12   \n",
       "566                 3                    3        11       16           1   \n",
       "\n",
       "     case_total_read_count  control_total_read_count case control chrom  \\\n",
       "0               790.045473                  0.000000   LT       S  chr6   \n",
       "1                25.663399                  0.000000   LT       S  chr6   \n",
       "2              3059.975520                  0.000000   LT       S  chr6   \n",
       "3               236.923721                  0.000000   LT       S  chr6   \n",
       "4               210.737582                  0.000000   LT       S  chr6   \n",
       "..                     ...                       ...  ...     ...   ...   \n",
       "559              28.026906                 75.798475   LT       S  chr6   \n",
       "563               2.593428                950.402410   LT       S  chr6   \n",
       "564              10.606703                 61.147122   LT       S  chr6   \n",
       "565            5597.302232                641.691134   LT       S  chr6   \n",
       "566              38.296036                 79.610095   LT       S  chr6   \n",
       "\n",
       "                        genes  \n",
       "0                     [Sndy1]  \n",
       "1               [Prrt4, tint]  \n",
       "2       [Gm31453, Hdp1, tint]  \n",
       "3                          []  \n",
       "4      [Aldh1l1, wa1l, Sndy1]  \n",
       "..                        ...  \n",
       "559    [Gm36408, Hdp1, Sndy1]  \n",
       "563        [Chl1, ssl, Sndy1]  \n",
       "564        [Grm7, ssl, Sndy1]  \n",
       "565                   [Sndy1]  \n",
       "566  [Gm43880, Hdp1, Cntnap2]  \n",
       "\n",
       "[409 rows x 20 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out insignificant pCISes to get CISes\n",
    "CIS_df = pCIS_df[\n",
    "    (pCIS_df[\"fishers_exact\"] <= pval_threshold) |\\\n",
    "    (pCIS_df[\"ranksums\"] <= pval_threshold) |\\\n",
    "    (pCIS_df[\"binomial\"] <= pval_threshold) ]\n",
    "CIS_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_index</th>\n",
       "      <th>case_pos_min</th>\n",
       "      <th>case_pos_max</th>\n",
       "      <th>control_index</th>\n",
       "      <th>control_pos_min</th>\n",
       "      <th>control_pos_max</th>\n",
       "      <th>ranksums</th>\n",
       "      <th>binomial</th>\n",
       "      <th>fishers_exact</th>\n",
       "      <th>case_num_samples</th>\n",
       "      <th>control_num_samples</th>\n",
       "      <th>total_IS</th>\n",
       "      <th>case_IS</th>\n",
       "      <th>control_IS</th>\n",
       "      <th>case_total_read_count</th>\n",
       "      <th>control_total_read_count</th>\n",
       "      <th>case</th>\n",
       "      <th>control</th>\n",
       "      <th>chrom</th>\n",
       "      <th>genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>86858017.0</td>\n",
       "      <td>86858024.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.953461e-02</td>\n",
       "      <td>3.889385e-62</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>204.786894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Aak1, wa1l, Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211</td>\n",
       "      <td>86976665.0</td>\n",
       "      <td>86976665.0</td>\n",
       "      <td>3.173105e-01</td>\n",
       "      <td>7.801456e-131</td>\n",
       "      <td>0.412903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>441.270860</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Aak1, wa1l, Sndy1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1</td>\n",
       "      <td>86910505.0</td>\n",
       "      <td>86911207.0</td>\n",
       "      <td>1</td>\n",
       "      <td>86886567.0</td>\n",
       "      <td>86910900.0</td>\n",
       "      <td>3.931046e-10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.355551</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>108</td>\n",
       "      <td>101</td>\n",
       "      <td>77</td>\n",
       "      <td>151431.857664</td>\n",
       "      <td>23456.878311</td>\n",
       "      <td>LT</td>\n",
       "      <td>S</td>\n",
       "      <td>chr6</td>\n",
       "      <td>[Aak1, wa1l, Sndy1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    case_index  case_pos_min  case_pos_max control_index  control_pos_min  \\\n",
       "5           14    86858017.0    86858024.0          None              NaN   \n",
       "354       None           NaN           NaN           211       86976665.0   \n",
       "534          1    86910505.0    86911207.0             1       86886567.0   \n",
       "\n",
       "     control_pos_max      ranksums       binomial  fishers_exact  \\\n",
       "5                NaN  4.953461e-02   3.889385e-62       1.000000   \n",
       "354       86976665.0  3.173105e-01  7.801456e-131       0.412903   \n",
       "534       86910900.0  3.931046e-10   0.000000e+00       0.355551   \n",
       "\n",
       "     case_num_samples  control_num_samples  total_IS  case_IS  control_IS  \\\n",
       "5                   1                    0         3        3           0   \n",
       "354                 0                    1         1        0           1   \n",
       "534                64                   50       108      101          77   \n",
       "\n",
       "     case_total_read_count  control_total_read_count case control chrom  \\\n",
       "5               204.786894                  0.000000   LT       S  chr6   \n",
       "354               0.000000                441.270860   LT       S  chr6   \n",
       "534          151431.857664              23456.878311   LT       S  chr6   \n",
       "\n",
       "                   genes  \n",
       "5    [Aak1, wa1l, Sndy1]  \n",
       "354  [Aak1, wa1l, Sndy1]  \n",
       "534  [Aak1, wa1l, Sndy1]  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a gene\n",
    "gene_search = \"Aak1\"\n",
    "CIS_df[CIS_df[\"genes\"].apply(lambda x: gene_search in x)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netcis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
